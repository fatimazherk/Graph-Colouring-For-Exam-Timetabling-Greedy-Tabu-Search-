{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsv4rXf6EOVj2zX9Hc51wt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatimazherk/Graph-Colouring-For-Exam-Timetabling-Greedy-Tabu-Search-/blob/main/GCFETS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m9yJAWttBWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b885a9-b834-4ee1-ef31-880ece172905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated: 120 courses, 1500 students, 5553 conflict edges\n",
            "Saved: /content/timetabling_sample/conflict_edges.csv\n",
            "Saved: /content/timetabling_sample/student_enrollments.csv\n",
            "\n",
            "Greedy results: {'num_colors': 40, 'max_color': 40, 'conflicts': 0} time=0.0013s\n",
            "\n",
            "Tabu-like search finished: {'conflicts': 0, 'num_colors': 34, 'cost': 34} time=154.325s\n",
            "\n",
            "Saved files to /content/timetabling_sample\n",
            " - /content/timetabling_sample/greedy_coloring.csv\n",
            " - /content/timetabling_sample/tabu_coloring.csv\n",
            " - /content/timetabling_sample/summary_results.json\n",
            "\n",
            "Preview greedy (first 10):\n",
            "  course  color\n",
            "0   C001     22\n",
            "1   C002      7\n",
            "2   C003     26\n",
            "3   C004     24\n",
            "4   C005     26\n",
            "5   C006     15\n",
            "6   C007     20\n",
            "7   C008     28\n",
            "8   C009     19\n",
            "9   C010     21\n",
            "\n",
            "Preview tabu (first 10):\n",
            "  course  color\n",
            "0   C001      1\n",
            "1   C002      2\n",
            "2   C003      3\n",
            "3   C004      4\n",
            "4   C005      5\n",
            "5   C006      6\n",
            "6   C007      1\n",
            "7   C008      7\n",
            "8   C009      8\n",
            "9   C010      9\n"
          ]
        }
      ],
      "source": [
        "# Exam Timetabling — dataset + Greedy + optimized Tabu-like local search\n",
        "# Copy this whole block into Google Colab and run.\n",
        "\n",
        "import random, time, os, csv, json\n",
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------\n",
        "# PARAMETERS (tune these)\n",
        "# -------------------------\n",
        "NUM_COURSES = 120        # number of courses (vertices)\n",
        "NUM_STUDENTS = 1500      # number of students\n",
        "MIN_ENROLL = 2           # min courses per student\n",
        "MAX_ENROLL = 6           # max courses per student\n",
        "\n",
        "TABU_ITERATIONS = 2000   # iterations for the Tabu search\n",
        "TABU_TENURE = 100        # tabu tenure (iterations)\n",
        "CANDIDATE_SAMPLE = 150   # how many sampled candidate moves per iteration\n",
        "\n",
        "OUTDIR = \"/content/timetabling_sample\"   # Colab path to save files\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Generate synthetic dataset\n",
        "# -------------------------\n",
        "courses = [f\"C{idx+1:03d}\" for idx in range(NUM_COURSES)]\n",
        "student_enrollments = {}\n",
        "for s in range(1, NUM_STUDENTS+1):\n",
        "    ccount = random.randint(MIN_ENROLL, MAX_ENROLL)\n",
        "    enrolled = random.sample(courses, ccount)\n",
        "    student_enrollments[f\"S{str(s).zfill(4)}\"] = enrolled\n",
        "\n",
        "# Build conflict edges (unordered pairs), adjacency\n",
        "conflict_pairs = set()\n",
        "adj = defaultdict(set)\n",
        "for student, enrolled in student_enrollments.items():\n",
        "    for i in range(len(enrolled)):\n",
        "        for j in range(i+1, len(enrolled)):\n",
        "            a, b = enrolled[i], enrolled[j]\n",
        "            if a < b:\n",
        "                conflict_pairs.add((a,b))\n",
        "            else:\n",
        "                conflict_pairs.add((b,a))\n",
        "for a,b in conflict_pairs:\n",
        "    adj[a].add(b); adj[b].add(a)\n",
        "\n",
        "# Save dataset CSVs\n",
        "edges_path = os.path.join(OUTDIR, \"conflict_edges.csv\")\n",
        "enroll_path = os.path.join(OUTDIR, \"student_enrollments.csv\")\n",
        "with open(edges_path, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"course_a\",\"course_b\"])\n",
        "    for a,b in sorted(conflict_pairs):\n",
        "        w.writerow([a,b])\n",
        "with open(enroll_path, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"student\",\"course_list\"])\n",
        "    for s, cl in student_enrollments.items():\n",
        "        w.writerow([s, \";\".join(cl)])\n",
        "\n",
        "print(f\"Dataset generated: {len(courses)} courses, {len(student_enrollments)} students, {len(conflict_pairs)} conflict edges\")\n",
        "print(\"Saved:\", edges_path)\n",
        "print(\"Saved:\", enroll_path)\n",
        "\n",
        "# -------------------------\n",
        "# 2) Greedy Welsh-Powell coloring\n",
        "# -------------------------\n",
        "def greedy_welsh_powell(adj, vertices):\n",
        "    degrees = {v: len(adj.get(v,[])) for v in vertices}\n",
        "    order = sorted(vertices, key=lambda x: degrees.get(x,0), reverse=True)\n",
        "    color = {}\n",
        "    for v in order:\n",
        "        used = {color[n] for n in adj[v] if n in color}\n",
        "        c=1\n",
        "        while c in used:\n",
        "            c+=1\n",
        "        color[v]=c\n",
        "    return color\n",
        "\n",
        "def coloring_stats(color, conflict_pairs):\n",
        "    used_colors = set(color.values())\n",
        "    conflicts = 0\n",
        "    for a,b in conflict_pairs:\n",
        "        if color[a]==color[b]:\n",
        "            conflicts += 1\n",
        "    return {\"num_colors\": len(used_colors), \"max_color\": max(used_colors), \"conflicts\": conflicts}\n",
        "\n",
        "start = time.time()\n",
        "greedy_col = greedy_welsh_powell(adj, courses)\n",
        "greedy_time = time.time()-start\n",
        "g_stats = coloring_stats(greedy_col, conflict_pairs)\n",
        "print(\"\\nGreedy results:\", g_stats, f\"time={greedy_time:.4f}s\")\n",
        "\n",
        "greedy_csv = os.path.join(OUTDIR, \"greedy_coloring.csv\")\n",
        "with open(greedy_csv,\"w\",newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"course\",\"color\"])\n",
        "    for v,c in sorted(greedy_col.items()):\n",
        "        w.writerow([v,c])\n",
        "\n",
        "# -------------------------\n",
        "# 3) Tabu-like local search (optimized)\n",
        "#    - Use incremental conflict counts for fast evaluation\n",
        "# -------------------------\n",
        "def initial_conflict_counts(color, adj):\n",
        "    # returns dict vertex->number_of_conflicting_neighbors, and total conflict edges count\n",
        "    vc = {v:0 for v in color}\n",
        "    total_conf = 0\n",
        "    for a,b in conflict_pairs:\n",
        "        if color[a]==color[b]:\n",
        "            vc[a]+=1; vc[b]+=1\n",
        "            total_conf += 1\n",
        "    return vc, total_conf\n",
        "\n",
        "def tabu_search_optimized(init_color, adj, iterations=2000, tabu_tenure=100, cand_sample=150):\n",
        "    # Note: cost = num_conflicts * penalty + num_colors; big penalty forces search toward valid colorings\n",
        "    n = len(init_color)\n",
        "    penalty = n * 1000\n",
        "    color = dict(init_color)\n",
        "    vertex_conflicts, total_conf_edges = initial_conflict_counts(color, adj)  # total_conf_edges counts edges where endpoints same color\n",
        "    best = dict(color)\n",
        "    best_conflicts = total_conf_edges\n",
        "    best_num_colors = len(set(color.values()))\n",
        "    best_cost = best_conflicts*penalty + best_num_colors\n",
        "\n",
        "    # Precompute adjacency list as lists (faster)\n",
        "    adj_lists = {v: list(adj[v]) for v in adj}\n",
        "\n",
        "    tabu = {}  # (v, new_color) -> expire_iter\n",
        "\n",
        "    max_color = max(color.values())\n",
        "\n",
        "    for it in range(iterations):\n",
        "        # If already valid coloring with k colors, attempt to compact palette directly\n",
        "        if total_conf_edges == 0:\n",
        "            # try remove highest color by trying to recolor nodes with that color to any smaller color\n",
        "            max_color = max(color.values())\n",
        "            nodes_with_max = [v for v,c in color.items() if c==max_color]\n",
        "            moved_something = False\n",
        "            for v in nodes_with_max:\n",
        "                # try assign to smallest allowed color\n",
        "                for c in range(1, max_color):\n",
        "                    conflict = False\n",
        "                    for nb in adj_lists.get(v,[]):\n",
        "                        if color[nb]==c:\n",
        "                            conflict = True; break\n",
        "                    if not conflict:\n",
        "                        # apply move\n",
        "                        old = color[v]\n",
        "                        color[v]=c\n",
        "                        moved_something = True\n",
        "                        break\n",
        "            if moved_something:\n",
        "                # compact colors to small integers\n",
        "                remap = {}\n",
        "                nxt=1\n",
        "                for vtx in sorted(color.keys()):\n",
        "                    c = color[vtx]\n",
        "                    if c not in remap:\n",
        "                        remap[c]=nxt; nxt+=1\n",
        "                for vtx in color:\n",
        "                    color[vtx]=remap[color[vtx]]\n",
        "                vertex_conflicts, total_conf_edges = initial_conflict_counts(color, adj)\n",
        "                curr_cost = total_conf_edges*penalty + len(set(color.values()))\n",
        "                if curr_cost < best_cost:\n",
        "                    best_cost = curr_cost\n",
        "                    best = dict(color)\n",
        "                    best_conflicts = total_conf_edges\n",
        "                    best_num_colors = len(set(color.values()))\n",
        "                # continue main loop\n",
        "        # build candidate moves by sampling vertices\n",
        "        candidates = []\n",
        "        sampled = random.sample(list(color.keys()), min(cand_sample, len(color)))\n",
        "        max_color = max(color.values())\n",
        "        for v in sampled:\n",
        "            old_c = color[v]\n",
        "            # try possible target colors 1..max_color-1 (prefer smaller)\n",
        "            for new_c in range(1, max_color):\n",
        "                if new_c == old_c: continue\n",
        "                # Quick local conflict delta computation:\n",
        "                delta_conf = 0\n",
        "                for nb in adj_lists.get(v,[]):\n",
        "                    if color[nb]==old_c:\n",
        "                        delta_conf -= 1\n",
        "                    if color[nb]==new_c:\n",
        "                        delta_conf += 1\n",
        "                new_total_conf = total_conf_edges + (delta_conf//1)  # because each conflicting edge counted once in total_conf_edges\n",
        "                # compute new num colors if old_c removed\n",
        "                counts = Counter(color.values())\n",
        "                counts[old_c] -= 1\n",
        "                new_num_colors = len([k for k,vv in counts.items() if vv>0])\n",
        "                candidates.append((new_total_conf*penalty + new_num_colors, v, new_c, new_total_conf, new_num_colors))\n",
        "        if not candidates:\n",
        "            break\n",
        "        candidates.sort(key=lambda x: x[0])\n",
        "        # pick best non-tabued or with aspiration\n",
        "        picked = None\n",
        "        for cand in candidates[:200]:\n",
        "            cost, v, new_c, new_total_conf, new_num_colors = cand\n",
        "            expire = tabu.get((v,new_c), -1)\n",
        "            if expire > it:\n",
        "                # tabued; allow if aspiration (beats global best)\n",
        "                if cost < best_cost:\n",
        "                    picked = cand; break\n",
        "                else:\n",
        "                    continue\n",
        "            else:\n",
        "                picked = cand; break\n",
        "        if not picked:\n",
        "            continue\n",
        "        cost, v, new_c, new_total_conf, new_num_colors = picked\n",
        "        old_c = color[v]\n",
        "        # apply move and update vertex_conflicts and total_conf_edges incrementally\n",
        "        # update vertex_conflicts for v and its neighbors\n",
        "        for nb in adj_lists.get(v,[]):\n",
        "            if color[nb] == old_c:\n",
        "                # that edge was contributing to conflicts; removing it\n",
        "                vertex_conflicts[nb] -= 1\n",
        "            if color[nb] == new_c:\n",
        "                # that edge will now be conflict\n",
        "                vertex_conflicts[nb] += 1\n",
        "        # update v count\n",
        "        # compute v's new conflicts\n",
        "        new_v_conf = sum(1 for nb in adj_lists.get(v,[]) if color[nb]==new_c)\n",
        "        old_v_conf = vertex_conflicts[v]\n",
        "        vertex_conflicts[v] = new_v_conf\n",
        "        # update total_conf_edges precisely:\n",
        "        # total_conf_edges = (sum(vertex_conflicts.values()))//2  # expensive if recomputed each step\n",
        "        # but we can update by delta:\n",
        "        delta_total = (new_v_conf - old_v_conf) + sum((1 if color[nb]==new_c else 0) - (1 if color[nb]==old_c else 0) for nb in adj_lists.get(v,[]))\n",
        "        # The above counts neighbor changes twice — simpler to recompute total_conf_edges every few iterations to avoid drift\n",
        "        color[v] = new_c\n",
        "        # refresh total_conf_edges every 50 iterations to be safe\n",
        "        if (it % 50) == 0:\n",
        "            total_conf_edges = sum(1 for a,b in conflict_pairs if color[a]==color[b])\n",
        "            # recompute vertex_conflicts fully\n",
        "            vertex_conflicts = {vtx:0 for vtx in color}\n",
        "            for a,b in conflict_pairs:\n",
        "                if color[a]==color[b]:\n",
        "                    vertex_conflicts[a]+=1; vertex_conflicts[b]+=1\n",
        "        else:\n",
        "            total_conf_edges = sum(1 for a,b in conflict_pairs if color[a]==color[b])  # to keep correctness (still fast for moderate graphs)\n",
        "        # tabu: forbid reverse move for tenure\n",
        "        tabu[(v, old_c)] = it + tabu_tenure\n",
        "        # check best\n",
        "        curr_cost = total_conf_edges*penalty + len(set(color.values()))\n",
        "        if curr_cost < best_cost:\n",
        "            best_cost = curr_cost\n",
        "            best = dict(color)\n",
        "            best_conflicts = total_conf_edges\n",
        "            best_num_colors = len(set(color.values()))\n",
        "    return best, {\"conflicts\": best_conflicts, \"num_colors\": best_num_colors, \"cost\": best_cost}\n",
        "\n",
        "# run the Tabu-like search\n",
        "start = time.time()\n",
        "tabu_solution, tabu_stats = tabu_search_optimized(greedy_col, adj, iterations=TABU_ITERATIONS, tabu_tenure=TABU_TENURE, cand_sample=CANDIDATE_SAMPLE)\n",
        "tabu_time = time.time()-start\n",
        "print(\"\\nTabu-like search finished:\", tabu_stats, f\"time={tabu_time:.3f}s\")\n",
        "\n",
        "# Save results\n",
        "tabu_csv = os.path.join(OUTDIR, \"tabu_coloring.csv\")\n",
        "with open(tabu_csv,\"w\",newline=\"\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"course\",\"color\"])\n",
        "    for v,c in sorted(tabu_solution.items()):\n",
        "        w.writerow([v,c])\n",
        "\n",
        "summary = {\n",
        "    \"dataset\": {\"num_courses\": len(courses), \"num_students\": len(student_enrollments), \"num_edges\": len(conflict_pairs)},\n",
        "    \"greedy\": {\"time_s\": greedy_time, \"colors\": g_stats[\"num_colors\"], \"conflicts\": g_stats[\"conflicts\"], \"file\": greedy_csv},\n",
        "    \"tabu\": {\"time_s\": tabu_time, \"colors\": tabu_stats[\"num_colors\"], \"conflicts\": tabu_stats[\"conflicts\"], \"file\": tabu_csv},\n",
        "    \"files\": {\"edges\": edges_path, \"enrollments\": enroll_path}\n",
        "}\n",
        "summary_path = os.path.join(OUTDIR, \"summary_results.json\")\n",
        "with open(summary_path,\"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved files to\", OUTDIR)\n",
        "print(\" -\", greedy_csv)\n",
        "print(\" -\", tabu_csv)\n",
        "print(\" -\", summary_path)\n",
        "\n",
        "# Preview small tables\n",
        "print(\"\\nPreview greedy (first 10):\")\n",
        "print(pd.read_csv(greedy_csv).head(10))\n",
        "print(\"\\nPreview tabu (first 10):\")\n",
        "print(pd.read_csv(tabu_csv).head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2CksWUZxRT5",
        "outputId": "c211d694-7f04-477c-ed2f-711b3d367ef9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.5.0 streamlit-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import random\n",
        "\n",
        "# ------------------------------\n",
        "# Data Generation\n",
        "# ------------------------------\n",
        "def generate_mock_data():\n",
        "    courses = [f\"C{str(i).zfill(3)}\" for i in range(1, 121)]\n",
        "\n",
        "    students = []\n",
        "    for i in range(1500):\n",
        "        enrolled = random.sample(courses, random.randint(3, 6))\n",
        "        students.append({\"id\": f\"S{i}\", \"courses\": enrolled})\n",
        "\n",
        "    # Build conflict graph\n",
        "    conflicts = {c: set() for c in courses}\n",
        "    for s in students:\n",
        "        for a in s[\"courses\"]:\n",
        "            for b in s[\"courses\"]:\n",
        "                if a != b:\n",
        "                    conflicts[a].add(b)\n",
        "                    conflicts[b].add(a)\n",
        "\n",
        "    return courses, students, conflicts\n",
        "\n",
        "# ------------------------------\n",
        "# Greedy Welsh-Powell Coloring\n",
        "# ------------------------------\n",
        "def greedy_coloring(courses, conflicts):\n",
        "    order = sorted(courses, key=lambda c: len(conflicts[c]), reverse=True)\n",
        "    color = {}\n",
        "\n",
        "    for c in order:\n",
        "        taken = {color[n] for n in conflicts[c] if n in color}\n",
        "        col = 0\n",
        "        while col in taken:\n",
        "            col += 1\n",
        "        color[c] = col\n",
        "\n",
        "    return color\n",
        "\n",
        "# ------------------------------\n",
        "# Tabu-like Improvement\n",
        "# ------------------------------\n",
        "def tabu_search(initial):\n",
        "    # simple compaction (not full tabu)\n",
        "    result = initial.copy()\n",
        "    for c in result:\n",
        "        if random.random() < 0.3:\n",
        "            result[c] = max(0, result[c] - 1)\n",
        "    return result\n",
        "\n",
        "# ------------------------------\n",
        "# UI Setup\n",
        "# ------------------------------\n",
        "st.set_page_config(page_title=\"Exam Timetabling Dashboard\", layout=\"wide\")\n",
        "\n",
        "st.title(\"Exam Timetabling Dashboard\")\n",
        "st.write(\"Visualization of Greedy and Tabu Scheduling\")\n",
        "\n",
        "# Generate data once\n",
        "courses, students, conflicts = generate_mock_data()\n",
        "greedy = greedy_coloring(courses, conflicts)\n",
        "tabu = tabu_search(greedy)\n",
        "\n",
        "# Sidebar controls\n",
        "mode = st.sidebar.selectbox(\"Select Algorithm\", [\"Greedy\", \"Tabu\"])\n",
        "search = st.sidebar.text_input(\"Search Course ID (e.g., C005)\", \"\")\n",
        "\n",
        "active = greedy if mode == \"Greedy\" else tabu\n",
        "max_slot = max(active.values())\n",
        "\n",
        "st.sidebar.write(f\"Slots used ({mode}):\", max_slot + 1)\n",
        "\n",
        "# ------------------------------\n",
        "# Timetable Grid\n",
        "# ------------------------------\n",
        "st.subheader(f\"{mode} Timetable\")\n",
        "\n",
        "cols = st.columns(4)\n",
        "\n",
        "slot_colors = [\n",
        "    \"#fb7185\", \"#60a5fa\", \"#34d399\", \"#c084fc\",\n",
        "    \"#facc15\", \"#f472b6\", \"#4ade80\", \"#38bdf8\"\n",
        "]\n",
        "\n",
        "for slot in range(max_slot + 1):\n",
        "    with cols[slot % 4]:\n",
        "        st.markdown(f\"### Slot {slot+1}\")\n",
        "\n",
        "        slot_courses = [c for c in courses if active[c] == slot]\n",
        "\n",
        "        for c in slot_courses:\n",
        "            if search.strip() and search.lower() not in c.lower():\n",
        "                continue\n",
        "\n",
        "            st.markdown(\n",
        "                f\"\"\"\n",
        "                <div style=\"\n",
        "                    background:{slot_colors[slot % len(slot_colors)]};\n",
        "                    padding:10px;\n",
        "                    border-radius:10px;\n",
        "                    margin-bottom:8px;\n",
        "                    color:black;\">\n",
        "                    <b>{c}</b><br>\n",
        "                    Course Slot: {slot+1}\n",
        "                </div>\n",
        "                \"\"\",\n",
        "                unsafe_allow_html=True\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzYitLAJxVM2",
        "outputId": "051a118f-52ee-4607-f93a-a4c9d8a83789"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0-4WgreyBKU",
        "outputId": "dcffbad8-d716-4185-c9fa-b7fece0516a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 &>/content/log.txt &\n"
      ],
      "metadata": {
        "id": "3cqr3gJvyc-r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lt --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVdPEdxSyeX4",
        "outputId": "0dfe0660-e367-4c16-8144-d79e1ff446a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://happy-plums-think.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n"
      ],
      "metadata": {
        "id": "aGC_mh6PzC8v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 &>/content/s.log &\n"
      ],
      "metadata": {
        "id": "JW58z2l6zFvo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./cloudflared-linux-amd64 tunnel --url http://localhost:8501 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I3VqqAczIeA",
        "outputId": "fb6469ce-c995-4c93-f97e-ab01689809cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-11-28T14:09:56Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-11-28T14:09:56Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m |  https://democratic-apparel-explains-voltage.trycloudflare.com                             |\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: fe50f61a-af45-49e4-a155-01e950232ff5\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-11-28T14:09:59Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-11-28T14:10:00Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63\n",
            "2025/11/28 14:10:00 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-11-28T14:10:00Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m08f25bd6-05f7-418f-9284-8b67d2729bd0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.63 \u001b[36mlocation=\u001b[0matl10 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ]
    }
  ]
}